{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete and Continuous Control with A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement learning (RL) is the study of agents taking actions in an environment in order to increase their \"reward\". This takes place in a perception-action-learning loop, whereby the agent receives an observation at every timestep, uses its policy to choose an action conditional on this observation, and then receives another observation and a scalar reward as the environment transitions to the next timestep. Through multiple interactions with the environment, the goal of the agent is to improve its policy so that it can maximise its expected cumulative reward.\n",
    "\n",
    "![RL Loop](https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/action-perception.png)\n",
    "\n",
    "Unlike the usual supervised or unsupervised learning settings, the agent is responsible for the data it receives, and so it is far from \"independent and identically distributed\". Furthermore, there is a particularly difficult credit assignment problem - the agent has to work out which of its actions result in rewards, where the rewards caused by the actions may appear a long time in the future. Nevertheless, RL provides a formal framework for studying this problem.\n",
    "\n",
    "Here we'll look at the advantage actor-critic (A2C) algorithm, which combines an explicit policy (the actor) with value function estimation (the critic); the value function captures the expected cumulative reward from a given state and given a certain policy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catrpole and pendulum?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
